{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>47</li>\n",
       "\t<li>16</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 47\n",
       "\\item 16\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 47\n",
       "2. 16\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 47 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read raw data\n",
    "df <- read.table('uscrime.txt', \n",
    "                 stringsAsFactors=FALSE,\n",
    "                 header=TRUE)\n",
    "final.test <-data.frame(M = 14.0,So = 0, Ed = 10.0, Po1 = 12.0, Po2 = 15.5,\n",
    "                  LF = 0.640, M.F = 94.0, Pop = 150, NW = 1.1, U1 = 0.120, \n",
    "                  U2 = 3.6, Wealth = 3200, Ineq = 20.1, Prob = 0.040,Time = 39.0)\n",
    "dim(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA essentially creates new features by finding vector orthogonal to the original data set's variance. Basically, we can extract the useful information, the variance per predictor, and only use those to build a model. Since the new features are orthogonal, we do not have to worry abobut multicollinearity. This, coupled with having a \"simpler\" model, can help with overfitting.\n",
    "  \n",
    "  \n",
    "It is important to note that the predictors used post-PCA are __new__ features. This means that to look for any form of interpretation, we must reverse the transformation process. \n",
    "  \n",
    "  \n",
    "Let us try out a simple example using the first 5 principal components for our data set and compare the results of using PCA transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test\n",
    "sample <- sample(nrow(df), nrow(df)*0.75)\n",
    "df.train <- df[sample,]\n",
    "df.test <- df[-sample,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "77.6949876023082"
      ],
      "text/latex": [
       "77.6949876023082"
      ],
      "text/markdown": [
       "77.6949876023082"
      ],
      "text/plain": [
       "[1] 77.69499"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predicting on all data\n",
    "lm1 <- lm(Crime~.,\n",
    "         data=df.train)\n",
    "\n",
    "pred <- predict(lm1, df.test[,1:15])\n",
    "ans <- df.test[,16]\n",
    "sqrt(mean(pred - ans)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "26.4953053318143"
      ],
      "text/latex": [
       "26.4953053318143"
      ],
      "text/markdown": [
       "26.4953053318143"
      ],
      "text/plain": [
       "[1] 26.49531"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm2 <- lm(Crime ~  M + Ed + Po1 + U2 + Ineq,\n",
    "          data = df.train)\n",
    "\n",
    "pred2 <- predict(lm2, df.test[,c('M', 'Ed', 'Po1', 'U2', 'Ineq')])\n",
    "ans2 <- df.test[,16]\n",
    "sqrt(mean(pred2 - ans2)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Crime ~ ., data = df.train)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-410.78  -89.24  -11.56   98.04  415.16 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)   \n",
       "(Intercept) -7.586e+03  2.501e+03  -3.033  0.00685 **\n",
       "M            9.766e+01  5.385e+01   1.813  0.08558 . \n",
       "So           5.047e+01  1.826e+02   0.276  0.78518   \n",
       "Ed           1.917e+02  7.702e+01   2.488  0.02228 * \n",
       "Po1          1.684e+02  1.338e+02   1.259  0.22337   \n",
       "Po2         -7.208e+01  1.485e+02  -0.485  0.63295   \n",
       "LF          -1.992e+03  1.832e+03  -1.087  0.29047   \n",
       "M.F          3.980e+01  2.716e+01   1.466  0.15914   \n",
       "Pop          1.242e+00  2.424e+00   0.512  0.61427   \n",
       "NW          -1.844e+00  9.191e+00  -0.201  0.84311   \n",
       "U1          -7.124e+03  5.624e+03  -1.267  0.22053   \n",
       "U2           1.467e+02  1.107e+02   1.325  0.20082   \n",
       "Wealth       7.153e-02  1.242e-01   0.576  0.57138   \n",
       "Ineq         7.386e+01  2.887e+01   2.558  0.01921 * \n",
       "Prob        -3.907e+03  2.684e+03  -1.456  0.16185   \n",
       "Time        -5.312e-02  8.759e+00  -0.006  0.99522   \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 226.6 on 19 degrees of freedom\n",
       "Multiple R-squared:  0.793,\tAdjusted R-squared:  0.6295 \n",
       "F-statistic: 4.852 on 15 and 19 DF,  p-value: 0.0008221\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Crime ~ M + Ed + Po1 + U2 + Ineq, data = df.train)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-463.82 -102.11   -8.17   98.72  552.73 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) -4906.19    1239.62  -3.958 0.000449 ***\n",
       "M              87.13      39.76   2.191 0.036620 *  \n",
       "Ed            172.61      57.98   2.977 0.005822 ** \n",
       "Po1           139.88      18.39   7.607 2.19e-08 ***\n",
       "U2             79.59      50.75   1.568 0.127675    \n",
       "Ineq           68.45      18.30   3.740 0.000807 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 216.6 on 29 degrees of freedom\n",
       "Multiple R-squared:  0.7112,\tAdjusted R-squared:  0.6614 \n",
       "F-statistic: 14.28 on 5 and 29 DF,  p-value: 4.42e-07\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all fairness, I should note that the lm2 model gives worse testing results than lm1 in some iterations. Here, a cross-validation approach could have been more useful as shown in Solutions for Homeowrk 5. However, the point remains that the Adjusted R-Squared for lm2 is much better than for lm1. \n",
    "  \n",
    "  \n",
    "Let us move on to using PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to training data\n",
    "pca <- prcomp(df.train[,1:15], scale.=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test\n",
    "# Keep only 5 principal components\n",
    "train3 <- data.frame(cbind(pca$x[,1:5], df.train[,16]))\n",
    "test3 <- data.frame(predict(pca, df.test[,1:15]))[,1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "lm3 <- lm(V6~.,\n",
    "         data=train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 <- predict(lm3, test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "28.962570355243"
      ],
      "text/latex": [
       "28.962570355243"
      ],
      "text/markdown": [
       "28.962570355243"
      ],
      "text/plain": [
       "[1] 28.96257"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sqrt(mean(pred3 - df.test[,16])^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = V6 ~ ., data = train3)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-434.29 -189.83   32.25  179.02  421.15 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)   865.89      42.33  20.457  < 2e-16 ***\n",
       "PC1            64.51      18.05   3.574  0.00125 ** \n",
       "PC2           -55.25      25.77  -2.144  0.04054 *  \n",
       "PC3           -62.25      29.99  -2.076  0.04688 *  \n",
       "PC4           -65.35      36.38  -1.797  0.08282 .  \n",
       "PC5          -199.22      43.23  -4.608 7.52e-05 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 250.4 on 29 degrees of freedom\n",
       "Multiple R-squared:  0.6141,\tAdjusted R-squared:  0.5475 \n",
       "F-statistic: 9.229 on 5 and 29 DF,  p-value: 2.425e-05\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see the affects of PCA first hand. We not only get a good testing score, but we have an ever lower R^2. While having a super low R^2 value is not what we are really looking for, we can see how the model saved from some overfitting whiel retaining as much information as possible for only have 5 \"predictors\".   \n",
    "  \n",
    "  \n",
    "It is important to note that refreshing and running the code leads to vastly different results with each iteration. Sometimes, the \"BEST\" score is from the overfit model - this is probably because there is not a lot of data at all. We will see an example later on why cross-validating would be a much better option, and how a single test case cannot be a good validation for such small data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> 480.078597718236"
      ],
      "text/latex": [
       "\\textbf{1:} 480.078597718236"
      ],
      "text/markdown": [
       "**1:** 480.078597718236"
      ],
      "text/plain": [
       "       1 \n",
       "480.0786 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(lm1, final.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> 1380.52758066187"
      ],
      "text/latex": [
       "\\textbf{1:} 1380.52758066187"
      ],
      "text/markdown": [
       "**1:** 1380.52758066187"
      ],
      "text/plain": [
       "       1 \n",
       "1380.528 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(lm2, final.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> 1282.52390742588"
      ],
      "text/latex": [
       "\\textbf{1:} 1282.52390742588"
      ],
      "text/markdown": [
       "**1:** 1282.52390742588"
      ],
      "text/plain": [
       "       1 \n",
       "1282.524 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(lm3, data.frame(predict(pca, final.test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how the PCA method also seems to help improve model accuracy in the way that looking for significant features does. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Model Building with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we see how PCA works, let us build a model using all of the data since the models before were made without a lot in the first place. Also, we can use cross-validation for the same reason.\n",
    "  \n",
    "  \n",
    "We will try two things here: PCA using all of the components, and PCA using only the first 5 as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: DAAG\n",
      "Loading required package: lattice\n"
     ]
    }
   ],
   "source": [
    "if (!require(\"DAAG\")) install.packages(\"DAAG\")\n",
    "library(DAAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Transform on full data\n",
    "df.x <- df[,1:15]\n",
    "df.y <- df[,16]\n",
    "\n",
    "# Use first 5 components, like before\n",
    "pca2 <- prcomp(df.x, scale.=TRUE)\n",
    "pca.x <- pca2$x\n",
    "df.pca <- data.frame(cbind(pca.x, df.y))\n",
    "\n",
    "df.pca.train <- df.pca[,c(1:5, 16)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All 15 Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build linear model\n",
    "final.lm.example <- lm(df.y~.,\n",
    "              df.pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of Variance Table\n",
      "\n",
      "Response: df.y\n",
      "          Df  Sum Sq Mean Sq F value  Pr(>F)    \n",
      "PC1        1 1177568 1177568   26.94 1.2e-05 ***\n",
      "PC2        1  633037  633037   14.48 0.00062 ***\n",
      "PC3        1   58541   58541    1.34 0.25599    \n",
      "PC4        1  257832  257832    5.90 0.02114 *  \n",
      "PC5        1 2312556 2312556   52.91 3.5e-08 ***\n",
      "PC6        1   92261   92261    2.11 0.15631    \n",
      "PC7        1  203535  203535    4.66 0.03879 *  \n",
      "PC8        1   11661   11661    0.27 0.60916    \n",
      "PC9        1   14950   14950    0.34 0.56289    \n",
      "PC10       1   29162   29162    0.67 0.42026    \n",
      "PC11       1    7564    7564    0.17 0.68027    \n",
      "PC12       1  494595  494595   11.32 0.00206 ** \n",
      "PC13       1   21336   21336    0.49 0.48996    \n",
      "PC14       1  129212  129212    2.96 0.09552 .  \n",
      "PC15       1   82173   82173    1.88 0.18017    \n",
      "Residuals 31 1354946   43708                    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "\n",
      "fold 1 \n",
      "Observations in test set: 11 \n",
      "               2    6  12  18  24    25   26    27     28    32    39\n",
      "Predicted   1474  793 722 844 869 605.9 1977 279.5 1258.5 807.8 839.3\n",
      "cvpred      1402  786 745 699 818 605.5 1744 331.9 1200.2 818.5 867.6\n",
      "df.y        1635  682 849 929 968 523.0 1993 342.0 1216.0 754.0 826.0\n",
      "CV residual  233 -104 104 230 150 -82.5  249  10.1   15.8 -64.5 -41.6\n",
      "\n",
      "Sum of squares = 226656    Mean square = 20605    n = 11 \n",
      "\n",
      "fold 2 \n",
      "Observations in test set: 12 \n",
      "                1   9    10   11    17   22   23   29   35   40  42   45\n",
      "Predicted   755.0 689 736.5 1161 393.4  657  958 1287  738 1131 326  617\n",
      "cvpred      764.7 674 796.2  980 505.2  814  655 1411  920 1310 293  738\n",
      "df.y        791.0 856 705.0 1674 539.0  439 1216 1043  653 1151 542  455\n",
      "CV residual  26.3 182 -91.2  694  33.8 -375  561 -368 -267 -159 249 -283\n",
      "\n",
      "Sum of squares = 1354557    Mean square = 112880    n = 12 \n",
      "\n",
      "fold 3 \n",
      "Observations in test set: 12 \n",
      "               5   7   14   15   20     21   33   37    38   44   46   47\n",
      "Predicted   1167 934  780  903 1228 774.85  841  971 562.7 1121  827  992\n",
      "cvpred       991 798  855 1172 1474 736.35  862 1511 642.9 1166  936 1317\n",
      "df.y        1234 963  664  798 1225 742.00 1072  831 566.0 1030  508  849\n",
      "CV residual  243 165 -191 -374 -249   5.65  210 -680 -76.9 -136 -428 -468\n",
      "\n",
      "Sum of squares = 1256692    Mean square = 104724    n = 12 \n",
      "\n",
      "fold 4 \n",
      "Observations in test set: 12 \n",
      "              3    4    8   13     16   19    30  31   34     36  41   43\n",
      "Predicted   322 1791 1362  733 1005.7 1146 702.7 388  971 1137.6 824 1134\n",
      "cvpred      159 1844 1238  762  932.7 1245 733.7 257 1026 1223.9 916 1246\n",
      "df.y        578 1969 1555  511  946.0  750 696.0 373  923 1272.0 880  823\n",
      "CV residual 419  125  317 -251   13.3 -495 -37.7 116 -103   48.1 -36 -423\n",
      "\n",
      "Sum of squares = 808153    Mean square = 67346    n = 12 \n",
      "\n",
      "Overall (Sum over all 12 folds) \n",
      "   ms \n",
      "77576 \n"
     ]
    }
   ],
   "source": [
    "# Arbitrarily chose 4 since other models also split data into 4 slices (75% train | 25% test)\n",
    "cv.example <- cv.lm(df.pca, final.lm.example, m=4,\n",
    "           plotit=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that although the overall error is 77576. Not the best, but also not too bad for the amount of data we have for our model. What is weird is how the mean square for EACH of the folds is so vastly different - the range is multiple times the minimum!\n",
    "  \n",
    "  \n",
    "We can move on to building it as we had before, with 5 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of Variance Table\n",
      "\n",
      "Response: df.y\n",
      "          Df  Sum Sq Mean Sq F value  Pr(>F)    \n",
      "PC1        1 1177568 1177568   19.78 6.5e-05 ***\n",
      "PC2        1  633037  633037   10.63  0.0022 ** \n",
      "PC3        1   58541   58541    0.98  0.3272    \n",
      "PC4        1  257832  257832    4.33  0.0437 *  \n",
      "PC5        1 2312556 2312556   38.84 2.0e-07 ***\n",
      "Residuals 41 2441394   59546                    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "\n",
      "fold 1 \n",
      "Observations in test set: 11 \n",
      "               2    6     12   18  24   25   26   27   28   32  39\n",
      "Predicted   1196  901 831.74 1098 929  604 1846  480 1015  970 628\n",
      "cvpred      1088 1025 849.78 1178 793  657 1612  614  908  982 671\n",
      "df.y        1635  682 849.00  929 968  523 1993  342 1216  754 826\n",
      "CV residual  547 -343  -0.78 -249 175 -134  381 -272  308 -228 155\n",
      "\n",
      "Sum of squares = 916770    Mean square = 83343    n = 11 \n",
      "\n",
      "fold 2 \n",
      "Observations in test set: 12 \n",
      "              1     9   10   11  17   22   23   29   35     40  42    45\n",
      "Predicted   714 862.7  906 1310 468  770  768 1464  915 1069.9 272 425.5\n",
      "cvpred      731 885.4  848 1402 390  810  769 1588  988 1117.2 159 432.1\n",
      "df.y        791 856.0  705 1674 539  439 1216 1043  653 1151.0 542 455.0\n",
      "CV residual  60 -29.4 -143  272 149 -371  447 -545 -335   33.8 383  22.9\n",
      "\n",
      "Sum of squares = 1016775    Mean square = 84731    n = 12 \n",
      "\n",
      "fold 3 \n",
      "Observations in test set: 12 \n",
      "               5   7    14  15     20    21   33   37    38   44   46   47\n",
      "Predicted   1004 818 653.8 663 1238.8 805.8  723 1212 604.3 1126  927 1139\n",
      "cvpred      1038 795 665.3 669 1263.5 841.7  734 1334 649.6 1185  933 1224\n",
      "df.y        1234 963 664.0 798 1225.0 742.0 1072  831 566.0 1030  508  849\n",
      "CV residual  196 168  -1.3 129  -38.5 -99.7  338 -503 -83.6 -155 -425 -375\n",
      "\n",
      "Sum of squares = 814840    Mean square = 67903    n = 12 \n",
      "\n",
      "fold 4 \n",
      "Observations in test set: 12 \n",
      "                3    4    8   13    16   19   30   31    34   36    41   43\n",
      "Predicted   506.4 1745 1158  669 933.8  975  802  688 841.7  978 841.5 1043\n",
      "cvpred      541.4 1636 1101  694 913.1  917  798  752 839.6  954 861.8 1021\n",
      "df.y        578.0 1969 1555  511 946.0  750  696  373 923.0 1272 880.0  823\n",
      "CV residual  36.6  333  454 -183  32.9 -167 -102 -379  83.4  318  18.2 -198\n",
      "\n",
      "Sum of squares = 682326    Mean square = 56860    n = 12 \n",
      "\n",
      "Overall (Sum over all 12 folds) \n",
      "   ms \n",
      "72994 \n"
     ]
    }
   ],
   "source": [
    "# Build linear model\n",
    "final.lm <- lm(df.y~.,\n",
    "              df.pca.train)\n",
    "\n",
    "# Arbitrarily chose 4 since other models also split data into 4 slices (75% train | 25% test)\n",
    "cv <- cv.lm(df.pca, final.lm, m=4,\n",
    "           plotit=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that while the overall ms is very similar, the folds are all much closer to one another. I believe that this shows robustness in our model, compared to the model before. Since all of the folds performed similarly, I think it is fair to say that the model is __consistent__ - not the mathematical definition, but in actual English. We can assume that the model will perform consistently for other data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.803086758316909"
      ],
      "text/latex": [
       "0.803086758316909"
      ],
      "text/markdown": [
       "0.803086758316909"
      ],
      "text/plain": [
       "[1] 0.803"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.645194053656692"
      ],
      "text/latex": [
       "0.645194053656692"
      ],
      "text/markdown": [
       "0.645194053656692"
      ],
      "text/plain": [
       "[1] 0.645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.501416354054191"
      ],
      "text/latex": [
       "0.501416354054191"
      ],
      "text/markdown": [
       "0.501416354054191"
      ],
      "text/plain": [
       "[1] 0.501"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SStot <- sum((df.y - mean(df.y))^2)\n",
    "SSres_model1 <- sum(final.lm.example$residuals^2)\n",
    "SSres_model2 <- sum(final.lm$residuals^2)\n",
    "\n",
    "SSres_c <- 72994*length(df.y)\n",
    "\n",
    "1-SSres_model1/SStot\n",
    "1-SSres_model2/SStot\n",
    "1-SSres_c/SStot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the R^2 calculation method from Hw5 Solutions, the results are not any different than what we saw then.  \n",
    "Basically, we see how using a bunch of components overfits - this applies even when using PCA rather than just the original variables. However, I do want to point out that the R^Squared for the PCA with 15 components is slightly lower than when using 15 variables, in the Hw 5 Solutions. \n",
    "  \n",
    "  \n",
    "What we really need to note here is looking at these R^2 values but also in combination with the testing scores. What does it say about a model if it has a great R^2 but a horrible testing score? It is overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the actual predictions made with our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 <- predict(final.lm, data.frame(predict(pca2, final.test)))\n",
    "pred15 <- predict(final.lm.example, data.frame(predict(pca2, final.test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>5 Comps</th><th scope=col>15 Comps</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1389</td><td>155 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " 5 Comps & 15 Comps\\\\\n",
       "\\hline\n",
       "\t 1389 & 155 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "5 Comps | 15 Comps | \n",
       "|---|\n",
       "| 1389 | 155  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  5 Comps 15 Comps\n",
       "1 1389    155     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results <- data.frame( c(pred5), c(pred15))\n",
    "colnames(results) = c('5 Comps', '15 Comps')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explanation from before is justified. The model using 15 principal components does horribly. This is significant because even though we got rid of multicollinearity, we are still using too many features for such a small data set. They are just adding noise or random error to the model, and our model is forced to fit to them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Reverting Model to Original Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are just getting the post-PCA model and translating back into the language of Crime Data. \n",
    "  \n",
    "  \n",
    "Principal Component so far has just applied a linear transformation to our data set. Basically, each principal component is a linear combination of the original crime predictors. (y = a1x1 + a2x2 ... means y is a linear combo of x, as long as a1 a2 etc are scalars).\n",
    "  \n",
    "  \n",
    "Since the model is a linear combination of the principal components (hence, the name linear model) we can substitute in values (basically just multiply) and then add them all up to get the model back into the language of our original data. First, however, we need to unscale the Principal Component Analysis data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = df.y ~ ., data = df.pca.train)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)          PC1          PC2          PC3          PC4          PC5  \n",
       "      905.1         65.2        -70.1         25.2         69.4       -229.0  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final.lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>PC1</th><th scope=col>PC2</th><th scope=col>PC3</th><th scope=col>PC4</th><th scope=col>PC5</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>M</th><td>-0.3037  </td><td> 0.06280 </td><td> 0.172420</td><td>-0.0204  </td><td>-0.3583  </td></tr>\n",
       "\t<tr><th scope=row>So</th><td>-0.3309  </td><td>-0.15837 </td><td> 0.015543</td><td> 0.2925  </td><td>-0.1206  </td></tr>\n",
       "\t<tr><th scope=row>Ed</th><td> 0.3396  </td><td> 0.21461 </td><td> 0.067740</td><td> 0.0797  </td><td>-0.0244  </td></tr>\n",
       "\t<tr><th scope=row>Po1</th><td> 0.3086  </td><td>-0.26982 </td><td> 0.050646</td><td> 0.3333  </td><td>-0.2353  </td></tr>\n",
       "\t<tr><th scope=row>Po2</th><td> 0.3110  </td><td>-0.26396 </td><td> 0.053065</td><td> 0.3519  </td><td>-0.2047  </td></tr>\n",
       "\t<tr><th scope=row>LF</th><td> 0.1762  </td><td> 0.31943 </td><td> 0.271530</td><td>-0.1433  </td><td>-0.3941  </td></tr>\n",
       "\t<tr><th scope=row>M.F</th><td> 0.1164  </td><td> 0.39434 </td><td>-0.203162</td><td> 0.0105  </td><td>-0.5788  </td></tr>\n",
       "\t<tr><th scope=row>Pop</th><td> 0.1131  </td><td>-0.46723 </td><td> 0.077021</td><td>-0.0321  </td><td>-0.0832  </td></tr>\n",
       "\t<tr><th scope=row>NW</th><td>-0.2936  </td><td>-0.22801 </td><td> 0.078816</td><td> 0.2393  </td><td>-0.3608  </td></tr>\n",
       "\t<tr><th scope=row>U1</th><td> 0.0405  </td><td> 0.00807 </td><td>-0.659029</td><td>-0.1828  </td><td>-0.1314  </td></tr>\n",
       "\t<tr><th scope=row>U2</th><td> 0.0181  </td><td>-0.27971 </td><td>-0.578501</td><td>-0.0689  </td><td>-0.1350  </td></tr>\n",
       "\t<tr><th scope=row>Wealth</th><td> 0.3797  </td><td>-0.07719 </td><td> 0.010065</td><td> 0.1178  </td><td> 0.0117  </td></tr>\n",
       "\t<tr><th scope=row>Ineq</th><td>-0.3658  </td><td>-0.02752 </td><td>-0.000294</td><td>-0.0807  </td><td>-0.2167  </td></tr>\n",
       "\t<tr><th scope=row>Prob</th><td>-0.2589  </td><td> 0.15832 </td><td>-0.117673</td><td> 0.4930  </td><td> 0.1656  </td></tr>\n",
       "\t<tr><th scope=row>Time</th><td>-0.0206  </td><td>-0.38015 </td><td> 0.223566</td><td>-0.5406  </td><td>-0.1476  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & PC1 & PC2 & PC3 & PC4 & PC5\\\\\n",
       "\\hline\n",
       "\tM & -0.3037   &  0.06280  &  0.172420 & -0.0204   & -0.3583  \\\\\n",
       "\tSo & -0.3309   & -0.15837  &  0.015543 &  0.2925   & -0.1206  \\\\\n",
       "\tEd &  0.3396   &  0.21461  &  0.067740 &  0.0797   & -0.0244  \\\\\n",
       "\tPo1 &  0.3086   & -0.26982  &  0.050646 &  0.3333   & -0.2353  \\\\\n",
       "\tPo2 &  0.3110   & -0.26396  &  0.053065 &  0.3519   & -0.2047  \\\\\n",
       "\tLF &  0.1762   &  0.31943  &  0.271530 & -0.1433   & -0.3941  \\\\\n",
       "\tM.F &  0.1164   &  0.39434  & -0.203162 &  0.0105   & -0.5788  \\\\\n",
       "\tPop &  0.1131   & -0.46723  &  0.077021 & -0.0321   & -0.0832  \\\\\n",
       "\tNW & -0.2936   & -0.22801  &  0.078816 &  0.2393   & -0.3608  \\\\\n",
       "\tU1 &  0.0405   &  0.00807  & -0.659029 & -0.1828   & -0.1314  \\\\\n",
       "\tU2 &  0.0181   & -0.27971  & -0.578501 & -0.0689   & -0.1350  \\\\\n",
       "\tWealth &  0.3797   & -0.07719  &  0.010065 &  0.1178   &  0.0117  \\\\\n",
       "\tIneq & -0.3658   & -0.02752  & -0.000294 & -0.0807   & -0.2167  \\\\\n",
       "\tProb & -0.2589   &  0.15832  & -0.117673 &  0.4930   &  0.1656  \\\\\n",
       "\tTime & -0.0206   & -0.38015  &  0.223566 & -0.5406   & -0.1476  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | PC1 | PC2 | PC3 | PC4 | PC5 | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| M | -0.3037   |  0.06280  |  0.172420 | -0.0204   | -0.3583   | \n",
       "| So | -0.3309   | -0.15837  |  0.015543 |  0.2925   | -0.1206   | \n",
       "| Ed |  0.3396   |  0.21461  |  0.067740 |  0.0797   | -0.0244   | \n",
       "| Po1 |  0.3086   | -0.26982  |  0.050646 |  0.3333   | -0.2353   | \n",
       "| Po2 |  0.3110   | -0.26396  |  0.053065 |  0.3519   | -0.2047   | \n",
       "| LF |  0.1762   |  0.31943  |  0.271530 | -0.1433   | -0.3941   | \n",
       "| M.F |  0.1164   |  0.39434  | -0.203162 |  0.0105   | -0.5788   | \n",
       "| Pop |  0.1131   | -0.46723  |  0.077021 | -0.0321   | -0.0832   | \n",
       "| NW | -0.2936   | -0.22801  |  0.078816 |  0.2393   | -0.3608   | \n",
       "| U1 |  0.0405   |  0.00807  | -0.659029 | -0.1828   | -0.1314   | \n",
       "| U2 |  0.0181   | -0.27971  | -0.578501 | -0.0689   | -0.1350   | \n",
       "| Wealth |  0.3797   | -0.07719  |  0.010065 |  0.1178   |  0.0117   | \n",
       "| Ineq | -0.3658   | -0.02752  | -0.000294 | -0.0807   | -0.2167   | \n",
       "| Prob | -0.2589   |  0.15832  | -0.117673 |  0.4930   |  0.1656   | \n",
       "| Time | -0.0206   | -0.38015  |  0.223566 | -0.5406   | -0.1476   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "       PC1     PC2      PC3       PC4     PC5    \n",
       "M      -0.3037  0.06280  0.172420 -0.0204 -0.3583\n",
       "So     -0.3309 -0.15837  0.015543  0.2925 -0.1206\n",
       "Ed      0.3396  0.21461  0.067740  0.0797 -0.0244\n",
       "Po1     0.3086 -0.26982  0.050646  0.3333 -0.2353\n",
       "Po2     0.3110 -0.26396  0.053065  0.3519 -0.2047\n",
       "LF      0.1762  0.31943  0.271530 -0.1433 -0.3941\n",
       "M.F     0.1164  0.39434 -0.203162  0.0105 -0.5788\n",
       "Pop     0.1131 -0.46723  0.077021 -0.0321 -0.0832\n",
       "NW     -0.2936 -0.22801  0.078816  0.2393 -0.3608\n",
       "U1      0.0405  0.00807 -0.659029 -0.1828 -0.1314\n",
       "U2      0.0181 -0.27971 -0.578501 -0.0689 -0.1350\n",
       "Wealth  0.3797 -0.07719  0.010065  0.1178  0.0117\n",
       "Ineq   -0.3658 -0.02752 -0.000294 -0.0807 -0.2167\n",
       "Prob   -0.2589  0.15832 -0.117673  0.4930  0.1656\n",
       "Time   -0.0206 -0.38015  0.223566 -0.5406 -0.1476"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PCA transformation values\n",
    "pca2$rotation[,1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>65.215930138666</li>\n",
       "\t<li>-70.0831185497856</li>\n",
       "\t<li>25.1940780425773</li>\n",
       "\t<li>69.4460307968387</li>\n",
       "\t<li>-229.042822001687</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 65.215930138666\n",
       "\\item -70.0831185497856\n",
       "\\item 25.1940780425773\n",
       "\\item 69.4460307968387\n",
       "\\item -229.042822001687\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 65.215930138666\n",
       "2. -70.0831185497856\n",
       "3. 25.1940780425773\n",
       "4. 69.4460307968387\n",
       "5. -229.042822001687\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]   65.2  -70.1   25.2   69.4 -229.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get linear model coef without intercept\n",
    "as.matrix(final.lm$coef)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X <- pca2$rotation[,1:5] \n",
    "Y <- final.lm$coef[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>M</th><td> 60.79</td></tr>\n",
       "\t<tr><th scope=row>So</th><td> 37.85</td></tr>\n",
       "\t<tr><th scope=row>Ed</th><td> 19.95</td></tr>\n",
       "\t<tr><th scope=row>Po1</th><td>117.34</td></tr>\n",
       "\t<tr><th scope=row>Po2</th><td>111.45</td></tr>\n",
       "\t<tr><th scope=row>LF</th><td> 76.25</td></tr>\n",
       "\t<tr><th scope=row>M.F</th><td>108.13</td></tr>\n",
       "\t<tr><th scope=row>Pop</th><td> 58.88</td></tr>\n",
       "\t<tr><th scope=row>NW</th><td> 98.07</td></tr>\n",
       "\t<tr><th scope=row>U1</th><td>  2.87</td></tr>\n",
       "\t<tr><th scope=row>U2</th><td> 32.35</td></tr>\n",
       "\t<tr><th scope=row>Wealth</th><td> 35.93</td></tr>\n",
       "\t<tr><th scope=row>Ineq</th><td> 22.10</td></tr>\n",
       "\t<tr><th scope=row>Prob</th><td>-34.64</td></tr>\n",
       "\t<tr><th scope=row>Time</th><td> 27.21</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "\tM &  60.79\\\\\n",
       "\tSo &  37.85\\\\\n",
       "\tEd &  19.95\\\\\n",
       "\tPo1 & 117.34\\\\\n",
       "\tPo2 & 111.45\\\\\n",
       "\tLF &  76.25\\\\\n",
       "\tM.F & 108.13\\\\\n",
       "\tPop &  58.88\\\\\n",
       "\tNW &  98.07\\\\\n",
       "\tU1 &   2.87\\\\\n",
       "\tU2 &  32.35\\\\\n",
       "\tWealth &  35.93\\\\\n",
       "\tIneq &  22.10\\\\\n",
       "\tProb & -34.64\\\\\n",
       "\tTime &  27.21\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| M |  60.79 | \n",
       "| So |  37.85 | \n",
       "| Ed |  19.95 | \n",
       "| Po1 | 117.34 | \n",
       "| Po2 | 111.45 | \n",
       "| LF |  76.25 | \n",
       "| M.F | 108.13 | \n",
       "| Pop |  58.88 | \n",
       "| NW |  98.07 | \n",
       "| U1 |   2.87 | \n",
       "| U2 |  32.35 | \n",
       "| Wealth |  35.93 | \n",
       "| Ineq |  22.10 | \n",
       "| Prob | -34.64 | \n",
       "| Time |  27.21 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "       [,1]  \n",
       "M       60.79\n",
       "So      37.85\n",
       "Ed      19.95\n",
       "Po1    117.34\n",
       "Po2    111.45\n",
       "LF      76.25\n",
       "M.F    108.13\n",
       "Pop     58.88\n",
       "NW      98.07\n",
       "U1       2.87\n",
       "U2      32.35\n",
       "Wealth  35.93\n",
       "Ineq    22.10\n",
       "Prob   -34.64\n",
       "Time    27.21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X %*% Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an intercept of 905.1, the values in the dataframe above show the coefficients for our final linear model using the 5 Principal Components. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
